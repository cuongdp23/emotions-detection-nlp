{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1sZ0wI3qvNK9haQ3EgshEuYWyRkgk9v9h","authorship_tag":"ABX9TyOjHdCntLi9aP4klHVFe/fQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["pip install emoji"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OXIWPvuoZuzx","executionInfo":{"status":"ok","timestamp":1715469861138,"user_tz":-420,"elapsed":9859,"user":{"displayName":"Phu Cuong","userId":"05728058720896257343"}},"outputId":"f3415e92-92e8-4a99-f75d-d14f0a89d306"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting emoji\n","  Downloading emoji-2.11.1-py2.py3-none-any.whl (433 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.8/433.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: emoji\n","Successfully installed emoji-2.11.1\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"yMB3SudWk2sq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install pyvi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YS-TozyT3iKs","executionInfo":{"status":"ok","timestamp":1715469874000,"user_tz":-420,"elapsed":12873,"user":{"displayName":"Phu Cuong","userId":"05728058720896257343"}},"outputId":"a87fee88-f2f7-4ca1-ead4-4486bb5b3834"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyvi\n","  Downloading pyvi-0.1.1-py2.py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pyvi) (1.2.2)\n","Collecting sklearn-crfsuite (from pyvi)\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.25.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pyvi) (3.5.0)\n","Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n","  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite->pyvi) (4.66.4)\n","Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n","Successfully installed python-crfsuite-0.9.10 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n"]}]},{"cell_type":"code","source":["import re\n","import emoji\n","import pandas as pd\n","from pyvi import ViTokenizer"],"metadata":{"id":"4qb7x6g6ZtHi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def remove_special_text(tweet):\n","  #Loại bỏ các kí tự và đường dẫn\n","  tweet = re.sub(r'(http\\S+)|(@\\S+)|RT|\\#|!|:|\\.|,', ' ', tweet)\n","  # Chuyển emoji sang text\n","  tweet = emoji.demojize(tweet)\n","  #Thêm dấu khoảng trắng trước và sau dấu text emoji\n","  tweet = re.sub(r'(:[a-zA-Z0-9_-]+:)', r' \\1 ', tweet)\n","\n","  tweet = tweet.replace('-', '_')\n","  tweet = tweet.replace(':', '_')\n","\n","  characters_to_remove = [' ̉ ', ' ̃ ', ' ̣ ', ' ́ ', ' ̀ ']\n","  for char in characters_to_remove:\n","    tweet = tweet.replace(char.strip(), '')\n","  return tweet\n","\n","\n","def correct_Word(tweet):\n","    # Chuẩn hóa từ theo tự điển\n","    errorWord_dict = pd.read_csv('/content/drive/MyDrive/KLTN/dictionary/error_word.csv')\n","    for index, row in errorWord_dict.iterrows():\n","        if row['incorrect_Word'] in tweet:\n","            tweet  = tweet.replace(row['incorrect_Word'], row['correct_Word'])\n","    return tweet\n","\n","\n","def tokenization(tweet):\n","  token_dict = pd.read_csv('/content/drive/MyDrive/KLTN/dictionary/token_word.csv')\n","  # Duyệt qua từng dòng trong từ điển token\n","  for index, row in token_dict.iterrows():\n","    # Nếu từ trong từ điển được tìm thấy trong tweet\n","    if row['Word'] in tweet:\n","    # Thay thế từ bằng token tương ứng\n","      tweet = tweet.replace(row['Word'], row['Token'])\n","\n","    # Thay thế các dấu gạch dưới kép bằng dấu gạch dưới duy nhất\n","    #tweet = tweet.replace('__', ' _')\n","\n","  return tweet\n","\n","def remove_stopWord(tweet):\n","    # Chuẩn hóa từ theo từ điển\n","    stopWord_dict = pd.read_csv('/content/drive/MyDrive/KLTN/dictionary/stop_word.csv')\n","    for index, row in stopWord_dict.iterrows():\n","        stop_word = row['stop_Word']\n","        # Loại bỏ stop word nếu nó xuất hiện trong tweet\n","        tweet = ' '.join([word for word in tweet.split() if word != stop_word])\n","    return tweet\n","\n","\n","def pre_process(tweet):\n","    tweet = remove_special_text(tweet)\n","    tweet = correct_Word(tweet)\n","    tweet = tokenization(tweet)\n","    tweet = remove_stopWord(tweet)\n","    tokens = ViTokenizer.tokenize(tweet)\n","    tokens = tokens.split()\n","    return tokens"],"metadata":{"id":"GXFYALHLdA6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_dataset(input_file, output_file):\n","    try:\n","        data = pd.read_csv(input_file, encoding='utf-8')\n","    except FileNotFoundError:\n","        print(\"File input không tồn tại!\")\n","        return\n","\n","    print(\"Input length:\", len(data))\n","    rows = []\n","\n","    for index, row in data.iterrows():\n","        tweet = row['Reviews']\n","        tokens = pre_process(tweet)\n","        sentiment = row['Sentiment']\n","        rows.append([sentiment, tokens, tweet])\n","\n","    df = pd.DataFrame(rows, columns=['Sentiment', 'Tokens', 'Reviews'])\n","\n","    df.to_csv(output_file, index=False, encoding='utf-8')\n","\n","\n","process_dataset('/content/drive/MyDrive/KLTN/input/UIT.csv', '/content/drive/MyDrive/KLTN/output/UIT_Final.csv')"],"metadata":{"id":"3uF3mlYv4C5-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0112621a-fae1-4bc9-b426-4da55e707e9b","executionInfo":{"status":"ok","timestamp":1715473413556,"user_tz":-420,"elapsed":3537113,"user":{"displayName":"Phu Cuong","userId":"05728058720896257343"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input length: 14876\n"]}]}]}